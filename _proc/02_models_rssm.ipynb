{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Recurrent SSM for Prior, Posterior and Transition.\n",
    "output-file: models_rssm.html\n",
    "title: RSSM\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### RSSM\n",
       "\n",
       ">      RSSM (action_size, rssm_node_size, embedding_size, device, rssm_type,\n",
       ">            info, act_fn=<class 'torch.nn.modules.activation.ELU'>)\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super(Model, self).__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### RSSM\n",
       "\n",
       ">      RSSM (action_size, rssm_node_size, embedding_size, device, rssm_type,\n",
       ">            info, act_fn=<class 'torch.nn.modules.activation.ELU'>)\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super(Model, self).__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(RSSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### RSSM.rssm_imagine\n",
       "\n",
       ">      RSSM.rssm_imagine (prev_action, prev_rssm_state, nonterms=True)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### RSSM.rssm_imagine\n",
       "\n",
       ">      RSSM.rssm_imagine (prev_action, prev_rssm_state, nonterms=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(RSSM.rssm_imagine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### RSSM.rollout_imagination\n",
       "\n",
       ">      RSSM.rollout_imagination (horizon:int,\n",
       ">                                actor:torch.nn.modules.module.Module,\n",
       ">                                prev_rssm_state)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### RSSM.rollout_imagination\n",
       "\n",
       ">      RSSM.rollout_imagination (horizon:int,\n",
       ">                                actor:torch.nn.modules.module.Module,\n",
       ">                                prev_rssm_state)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(RSSM.rollout_imagination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### RSSM.rssm_observe\n",
       "\n",
       ">      RSSM.rssm_observe (obs_embed, prev_action, prev_nonterm, prev_rssm_state)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### RSSM.rssm_observe\n",
       "\n",
       ">      RSSM.rssm_observe (obs_embed, prev_action, prev_nonterm, prev_rssm_state)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(RSSM.rssm_observe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### RSSM.rollout_observation\n",
       "\n",
       ">      RSSM.rollout_observation (seq_len:int, obs_embed:torch.Tensor,\n",
       ">                                action:torch.Tensor, nonterms:torch.Tensor,\n",
       ">                                prev_rssm_state)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### RSSM.rollout_observation\n",
       "\n",
       ">      RSSM.rollout_observation (seq_len:int, obs_embed:torch.Tensor,\n",
       ">                                action:torch.Tensor, nonterms:torch.Tensor,\n",
       ">                                prev_rssm_state)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(RSSM.rollout_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14043d84",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45511982",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa9ff7",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
